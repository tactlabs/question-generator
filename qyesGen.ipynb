{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qyesGen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CcQYwrgtoSi"
      },
      "source": [
        "# !pip install sentence-transformers\n",
        "# !pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ1xiuGmtuRD"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, BertTokenizer, BertModel, AutoTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "import spacy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JdQkoSfuAJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f50e99c-1abb-411c-c495-fd86dfe3fdba"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from warnings import filterwarnings as filt\n",
        "\n",
        "filt('ignore')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlZV6Po58lrT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB6nzMuT9XVC"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_question(sentence, answer):\n",
        "\n",
        "  mdl = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "  tknizer = AutoTokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "\n",
        "  text = \"context: {} answer: {}\".format(sentence,answer)\n",
        "  max_len = 256\n",
        "  encoding = tknizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = mdl.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=5,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  max_length=300)\n",
        "\n",
        "\n",
        "  dec = [tknizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
        "\n",
        "\n",
        "  Question = dec[0].replace(\"question:\",\"\")\n",
        "  Question= Question.strip()\n",
        "  return Question\n",
        "\n",
        "def get_embedding(doc):\n",
        "\n",
        "  bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "  \n",
        "  # txt = '[CLS] ' + doc + ' [SEP]'\n",
        "  tokens = bert_tokenizer.tokenize(txt)\n",
        "  token_idx = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
        "  segment_ids = [1] * len(tokens)\n",
        "\n",
        "  torch_token = torch.tensor([token_idx])\n",
        "  torch_segment = torch.tensor([segment_ids])\n",
        "\n",
        "  return bert_model(torch_token, torch_segment)[-1].detach().numpy()\n",
        "\n",
        "def get_pos(context):\n",
        "  doc = nlp(context)\n",
        "  docs = [d.pos_ for d in doc]\n",
        "  return docs, context.split()\n",
        "\n",
        "def get_sent(context):\n",
        "  doc = nlp(context)\n",
        "  return list(doc.sents)\n",
        "\n",
        "def get_vector(doc):\n",
        "  stop_words = \"english\"\n",
        "  n_gram_range = (1,1)\n",
        "  df = CountVectorizer(ngram_range = n_gram_range, stop_words = stop_words).fit([doc])\n",
        "  return df.get_feature_names()\n",
        "\n",
        "\n",
        "def get_key_words(context, module_type = 't'):\n",
        "  keywords = []\n",
        "  top_n = 5\n",
        "  for txt in get_sent(context):\n",
        "    keywd = get_vector(str(txt))\n",
        "    print(f'vectors : {keywd}')\n",
        "    if module_type == 't':\n",
        "      doc_embedding = get_embedding(str(txt))\n",
        "      keywd_embedding = get_embedding(' '.join(keywd))\n",
        "    else:\n",
        "      doc_embedding = model.encode([str(txt)])\n",
        "      keywd_embedding = model.encode(keywd)\n",
        "    \n",
        "    distances = cosine_similarity(doc_embedding, keywd_embedding)\n",
        "    print(distances)\n",
        "    keywords += [(keywd[index], str(txt)) for index in distances.argsort()[0][-top_n:]]\n",
        "\n",
        "  return keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6kJs35X95Hz"
      },
      "source": [
        "txt = 'Mauricio Pochettino open to leaving Paris St-Germain if Man Utd make approach'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTZvqMyrLqIZ"
      },
      "source": [
        "# generating questions based on the above txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fkS_Lqg9_Po",
        "outputId": "78b83c45-1ffb-4115-a630-8e3e430e2603"
      },
      "source": [
        "# this will use my own embedding \n",
        "get_key_words(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vectors : ['approach', 'germain', 'leaving', 'make', 'man', 'mauricio', 'open', 'paris', 'pochettino', 'st', 'utd']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('approach',\n",
              "  'Mauricio Pochettino open to leaving Paris St-Germain if Man Utd make approach')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE585EyyBRJa",
        "outputId": "a60f3cd5-8d7f-42c9-9be2-fbb4b0ebe63c"
      },
      "source": [
        "# this will use sentence transformers embedding and this is working pretty good \n",
        "txt = 'Mauricio Pochettino open to leaving Paris St-Germain if Man Utd make approach'\n",
        "for ans, context in get_key_words(txt, 'st'):\n",
        "  print('=======================================')\n",
        "  print()\n",
        "  print(get_question(context, ans))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vectors : ['approach', 'germain', 'leaving', 'make', 'man', 'mauricio', 'open', 'paris', 'pochettino', 'st', 'utd']\n",
            "[[0.38606027 0.47576404 0.36602828 0.28078705 0.31993675 0.4191036\n",
            "  0.47562945 0.5885888  0.40264377 0.30833414 0.33931935]]\n",
            "=======================================\n",
            "\n",
            "Who is open to leaving Paris St-Germain if Man Utd make an approach?\n",
            "\n",
            "=======================================\n",
            "\n",
            "Who is open to leaving Paris St-Germain if Man Utd make an approach?\n",
            "\n",
            "=======================================\n",
            "\n",
            "Is Mauricio Pochettino open to leaving Paris St-Germain?\n",
            "\n",
            "=======================================\n",
            "\n",
            "Pochettino is open to leaving Paris St-Germain if Man Utd make an approach?\n",
            "\n",
            "=======================================\n",
            "\n",
            "What city is Mauricio Pochettino open to leaving if Man Utd make an approach?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYN1E9wIGzjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205dbc4c-9607-4ede-eb89-12ab0e93c2ac"
      },
      "source": [
        "{'cat' for _ in range(5)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tUNi2Yi0xgx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}